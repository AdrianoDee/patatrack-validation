#! /bin/bash -e

# Script for testing one or more pull requests against a reference release and an intermediate development release
#
# Usage:
#   validate [PR ...]
#
# Note: this script relies on `visDQMUpload` and `visDQMUtils.py` being available in the same directory.
# If they are missing they are automatically downloaded from https://github.com/rovere/dqmgui/ .

# Directory with the validation scripts
VALIDATION=$(readlink -f $(dirname ${BASH_SOURCE[0]}))

# Create a temporay working directory
BASE=$(mktemp -d -p $PWD run.XXXXXXXXXX)
[ -d $BASE ] || exit 1
REPORT=$BASE/report.md

# save the original file descriptors, then redirect all output and errors to a log file
exec 3>&1 4>&2
exec &> $BASE/log

# Local configuration - should go before the others
source local.sh

# CMSSW configuration
source cmssw.sh

# DQM configuration
source dqm.sh

# GitHub-related configuration
source github.sh

# Input samples configuration
source input.sh

# Hash of this script and its configuration
SCRIPTHASH=$(cat $VALIDATION/*.sh ${BASH_SOURCE[0]} | sha1sum | cut -d' ' -f1)

# cuda-memcheck tools options
INITCHECK_OPTS="--track-unused-memory no"
MEMCHECK_OPTS="--leak-check full --report-api-errors all"
SYNCCHECK_OPTS=""

function report() {
  echo "$@" >> $REPORT
}

function apply() {
  PATTERN="$1"; shift
    for ARG; do echo $PATTERN | sed -e"s/%/$ARG/g"; done
}

function apply_and_glob() {
  echo $(apply "$@")
}

function has_validate() {
  local WORKFLOW=$1
  echo "$VALIDATE" | grep -q -w "$WORKFLOW"
}

function has_profiling() {
  local WORKFLOW=$1
  echo "$PROFILING" | grep -q -w "$WORKFLOW"
}

function has_memcheck() {
  local WORKFLOW=$1
  echo "$MEMCHECKS" | grep -q -w "$WORKFLOW"
}

function build_matrix() {
  local DIRNAME="$1"
  shift
  local WORKFLOWS="$@"
  local SAMPLE DATASET WORKDIR CACHE_PATH CACHE_FILE INPUT MY_GLOBALTAG MY_NUMEVENTS WORKFLOW
  # create the matrix-like workflows for the various samples
  cd $BASE/$DIRNAME
  eval $(scram runtime -sh)
  for SAMPLE in $SAMPLES; do
    DATASET=${!SAMPLE}
    WORKDIR=$(echo $DATASET | cut -d/ -f 2-3 --output-delimiter=-)
    CACHE_PATH=$(eval echo \$$(echo $SAMPLE)_CACHE_PATH)
    CACHE_FILE=$(eval echo \$$(echo $SAMPLE)_CACHE_FILE)
    if [ "$CACHE_PATH" ] && [ "$CACHE_FILE" ]; then
      INPUT="--dirin=$CACHE_PATH --filein $CACHE_FILE"
    else
      INPUT="--dasquery 'file dataset=$DATASET'"
    fi
    # customise the global tag and number of events by dataset, or use the default values
    MY_GLOBALTAG=$(eval echo \$$(echo $SAMPLE)_GLOBALTAG)
    MY_NUMEVENTS=$(eval echo \$$(echo $SAMPLE)_NUMEVENTS)
    echo "# prepare to run on ${MY_NUMEVENTS:=$NUMEVENTS} events on $DATASET with ${MY_GLOBALTAG:=$GLOBALTAG} conditions"
    mkdir -p $CMSSW_BASE/run/$WORKDIR
    cd $CMSSW_BASE/run/$WORKDIR
    for WORKFLOW in $WORKFLOWS; do
      # check the the workflow actually exists in the release
      runTheMatrix.py -n -e -l $WORKFLOW | grep -q ^$WORKFLOW || continue
      mkdir -p $WORKFLOW
      cd $WORKFLOW

      # extract step3 and step4 commands
      local STEP3="$(runTheMatrix.py -n -e -l $WORKFLOW | grep 'cmsDriver.py step3' | cut -d: -f2- | sed -e"s/^ *//" -e"s/ \+--conditions *[^ ]\+/ --conditions $MY_GLOBALTAG/" -e"s/ \+-n *[^ ]\+/ -n $MY_NUMEVENTS/") --fileout file:step3.root"
      local STEP4="$(runTheMatrix.py -n -e -l $WORKFLOW | grep 'cmsDriver.py step4' | cut -d: -f2- | sed -e"s/^ *//" -e"s/ \+--conditions *[^ ]\+/ --conditions $MY_GLOBALTAG/" -e"s/ \+-n *[^ ]\+/ -n $MY_NUMEVENTS/") --filein file:step3_inDQM.root"

      if has_validate $WORKFLOW; then
        echo "# prepare workflow $WORKFLOW"
        $STEP3 $INPUT --no_exec --python_filename=step3.py
        $STEP4        --no_exec --python_filename=step4.py
        # show CUDAService messages and configure multithreading
        cat >> step3.py << @EOF

# Show CUDAService messages
process.MessageLogger.categories.append("CUDAService")

# Configure multithreading
process.options.numberOfThreads = cms.untracked.uint32( $THREADS )
process.options.numberOfStreams = cms.untracked.uint32( $STREAMS )
@EOF
      fi

      local PROFILING_FILE=RecoPixelVertexing/Configuration/customizePixelTracksForProfiling
      local PROFILING_FUNC=customizePixelTracksForProfilingGPUOnly
      if has_profiling $WORKFLOW && ( [ -f $CMSSW_RELEASE_BASE/python/${PROFILING_FILE}.py ] || [ -f $CMSSW_BASE/python/${PROFILING_FILE}.py ] ); then
        # create a profiling workflow
        $STEP3 $INPUT --no_exec --customise_unsch ${PROFILING_FILE}.${PROFILING_FUNC} --python_filename=profile.py
        # add the NVProfilerService to profile, show CUDAService messages and configure multithreading
        cat >> profile.py << @EOF

# Mark CMSSW transitions and modules in the nvprof profile
from FWCore.ParameterSet.Utilities import moduleLabelsInSequences
process.NVProfilerService = cms.Service("NVProfilerService",
    highlightModules = cms.untracked.vstring( moduleLabelsInSequences(process.reconstruction_step) ),
    showModulePrefetching = cms.untracked.bool( False )
)

# Show CUDAService messages
process.MessageLogger.categories.append("CUDAService")

# Configure multithreading
process.options.numberOfThreads = cms.untracked.uint32( $THREADS )
process.options.numberOfStreams = cms.untracked.uint32( $STREAMS )
@EOF
      fi

      if has_memcheck $WORKFLOW; then
        # prepare the workflow to run the various cuda-memcheck checks
        cp step3.py memcheck.py
        (( MEMCHECK_NUMEVENTS )) || local MEMCHECK_NUMEVENTS=10
        cat >> memcheck.py << @EOF

# Set the number of events for the memcheck workflows
process.maxEvents = cms.untracked.PSet(
    input = cms.untracked.int32($MEMCHECK_NUMEVENTS)
)
@EOF
      fi

      cd ..
    done
    echo
  done
}

function build_data_matrix() {
  local DIRNAME="$1"
  shift
  local WORKFLOWS="$@"
  local SAMPLE DATASET WORKDIR CACHE_PATH CACHE_FILE INPUT MY_GLOBALTAG MY_NUMEVENTS WORKFLOW
  # create the matrix-like workflows for the various samples
  cd $BASE/$DIRNAME
  eval $(scram runtime -sh)
  for SAMPLE in $DATA_SAMPLES; do
    DATASET=${!SAMPLE}
    WORKDIR=$(echo $DATASET | cut -d/ -f 2-3 --output-delimiter=-)
    CACHE_PATH=$(eval echo \$$(echo $SAMPLE)_CACHE_PATH)
    CACHE_FILE=$(eval echo \$$(echo $SAMPLE)_CACHE_FILE)
    if [ "$CACHE_PATH" ] && [ "$CACHE_FILE" ]; then
      INPUT="--dirin=$CACHE_PATH --filein $CACHE_FILE"
    else
      INPUT="--dasquery 'file dataset=$DATASET'"
    fi
    # customise the global tag and number of events by dataset, or use the default values
    MY_GLOBALTAG=$(eval echo \$$(echo $SAMPLE)_GLOBALTAG)
    MY_NUMEVENTS=$(eval echo \$$(echo $SAMPLE)_NUMEVENTS)
    echo "# prepare to run on ${MY_NUMEVENTS:=$NUMEVENTS} events on $DATASET with ${MY_GLOBALTAG:=$GLOBALTAG} conditions"
    mkdir -p $CMSSW_BASE/run/$WORKDIR
    cd $CMSSW_BASE/run/$WORKDIR
    for WORKFLOW in $WORKFLOWS; do
      # check the the workflow actually exists in the release
      runTheMatrix.py -n -e -l $WORKFLOW | grep -q ^$WORKFLOW || continue
      mkdir -p $WORKFLOW
      cd $WORKFLOW

      # copy the custom source modules
      cp $VALIDATION/parts/sourceFromRaw_${WORKDIR}_cff.py sourceFromRaw_cff.py

      # extract step3 and step4 commands
      local STEP3="$(runTheMatrix.py -n -e -l $WORKFLOW | grep 'cmsDriver.py step3' | cut -d: -f2- | sed -e"s/^ *//" -e"s/ \+--conditions *[^ ]\+/ --conditions $MY_GLOBALTAG/" -e"s/ \+-n *[^ ]\+/ -n $MY_NUMEVENTS/") --fileout file:step3.root"
      local STEP4="$(runTheMatrix.py -n -e -l $WORKFLOW | grep 'cmsDriver.py step4' | cut -d: -f2- | sed -e"s/^ *//" -e"s/ \+--conditions *[^ ]\+/ --conditions $MY_GLOBALTAG/" -e"s/ \+-n *[^ ]\+/ -n $MY_NUMEVENTS/") --filein file:step3_inDQM.root"

      if has_validate $WORKFLOW; then
        echo "# prepare workflow $WORKFLOW"
        $STEP3 $INPUT --no_exec --python_filename=step3.py
        $STEP4        --no_exec --python_filename=step4.py
        # show CUDAService messages and configure multithreading
        cat >> step3.py << @EOF

# Override the source to use the DAQ source
import sys, os, inspect
sys.path.append(os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))))
process.load("sourceFromRaw_cff")

# Show CUDAService messages
process.MessageLogger.categories.append("CUDAService")

# Configure multithreading
process.options.numberOfThreads = cms.untracked.uint32( $THREADS )
process.options.numberOfStreams = cms.untracked.uint32( $STREAMS )
@EOF
      fi

      local PROFILING_FILE=RecoPixelVertexing/Configuration/customizePixelTracksForProfiling
      local PROFILING_FUNC=customizePixelTracksForProfilingGPUOnly
      if has_profiling $WORKFLOW && ( [ -f $CMSSW_RELEASE_BASE/python/${PROFILING_FILE}.py ] || [ -f $CMSSW_BASE/python/${PROFILING_FILE}.py ] ); then
        # create a profiling workflow
        $STEP3 $INPUT --no_exec --customise_unsch ${PROFILING_FILE}.${PROFILING_FUNC} --python_filename=profile.py
        # add the NVProfilerService to profile, show CUDAService messages and configure multithreading
        cat >> profile.py << @EOF

# Override the source to use the DAQ source
import sys, os, inspect
sys.path.append(os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))))
process.load("sourceFromRaw_cff")

# Mark CMSSW transitions and modules in the nvprof profile
from FWCore.ParameterSet.Utilities import moduleLabelsInSequences
process.NVProfilerService = cms.Service("NVProfilerService",
    highlightModules = cms.untracked.vstring( moduleLabelsInSequences(process.reconstruction_step) ),
    showModulePrefetching = cms.untracked.bool( False )
)

# Show CUDAService messages
process.MessageLogger.categories.append("CUDAService")

# Configure multithreading
process.options.numberOfThreads = cms.untracked.uint32( $THREADS )
process.options.numberOfStreams = cms.untracked.uint32( $STREAMS )
@EOF
      fi

      if has_memcheck $WORKFLOW; then
        # prepare the workflow to run the various cuda-memcheck checks
        cp step3.py memcheck.py
        (( MEMCHECK_NUMEVENTS )) || local MEMCHECK_NUMEVENTS=10
        cat >> memcheck.py << @EOF

# Set the number of events for the memcheck workflows
process.maxEvents = cms.untracked.PSet(
    input = cms.untracked.int32($MEMCHECK_NUMEVENTS)
)
@EOF
      fi

      cd ..
    done
    echo
  done
}


function run_workflow() {
  local WORKDIR="$1"

  cd $BASE/$WORKDIR
  echo "# at $WORKDIR"
  eval $(scram runtime -sh)

  # (optional) run the validation
  if [ -f step3.py ]; then
    # run step 3
    echo -n "# running step3... "
    if cmsRun step3.py >& step3.log; then
      echo "done"
      touch step3.done
    else
      echo "failed"
      tail step3.log
      touch step3.fail
      # do not attempt to run other steps if step3 failed
      cd $BASE
      return
    fi

    # run step 4
    echo -n "# running step4... "
    if cmsRun step4.py >& step4.log; then
      echo "done"
      touch step4.done
    else
      echo "failed"
      tail step4.log
      touch step4.fail
    fi
  fi

  # (optional) run profile
  if [ -f profile.py ]; then
    echo -n "# running profile... "
    if nvprof -f -o profile.nvvp -s --log-file profile.profile -- cmsRun profile.py >& profile.log; then
      echo "done"
      touch profile.done
    else
      echo "failed"
      tail profile.log
      touch profile.fail
    fi
  fi

  # (optional) run cuda-memcheck
  if [ -f memcheck.py ]; then
    # initcheck
    echo -n "# running cuda-memcheck --tool initcheck... "
    if cuda-memcheck --tool initcheck --error-exitcode 127 $SYNCCHECK_OPTS --log-file initcheck.out -- cmsRun memcheck.py >& initcheck.log; then
      [ -f initcheck.log ] && cat initcheck.log | c++filt -i > demangled && mv demangled initcheck.log
      echo "done"
      touch cuda-initcheck.done
    else
      echo "failed"
      tail initcheck.out
      touch cuda-initcheck.fail
    fi
    # memcheck
    echo -n "# running cuda-memcheck --tool memcheck... "
    if cuda-memcheck --tool memcheck --error-exitcode 127 $MEMCHECK_OPTS --log-file memcheck.out -- cmsRun memcheck.py >& memcheck.log; then
      [ -f memcheck.log ] && cat memcheck.log | c++filt -i > demangled && mv demangled memcheck.log
      echo "done"
      touch cuda-memcheck.done
    else
      echo "failed"
      tail memcheck.out
      touch cuda-memcheck.fail
    fi
    # synccheck
    echo -n "# running cuda-memcheck --tool synccheck... "
    if cuda-memcheck --tool synccheck --error-exitcode 127 $SYNCCHECK_OPTS --log-file synccheck.out -- cmsRun memcheck.py >& synccheck.log; then
      [ -f synccheck.log ] && cat synccheck.log | c++filt -i > demangled && mv demangled synccheck.log
      echo "done"
      touch cuda-synccheck.done
    else
      echo "failed"
      tail synccheck.out
      touch cuda-synccheck.fail
    fi
  fi

  cd $BASE
}

function run_workflows() {
  cd $BASE

  local WORKDIR
  for WORKDIR in $(apply_and_glob "%/run/*/*/" "$@"); do
    run_workflow $WORKDIR
  done
}

function run_workflows_in_parallel() {
  cd $BASE

  # create a named pipe
  local FIFO=$(mktemp -u pipeXXXXXXXXXX)
  mkfifo $FIFO
  exec 3<>$FIFO
  rm $FIFO

  # put in the fifo a token per GPU
  local GPU
  local TOKEN
  nvidia-smi -L | cut -d: -f1 | while read GPU TOKEN; do
    printf "%s," "$TOKEN" >&3
  done

  local MAXJOBS=$(($1))
  local WORKDIR
  for WORKDIR in $(apply_and_glob "%/run/*/*/" "$@"); do
    # block until a token is available
    local TOKEN
    read -u3 -d, TOKEN

    (
      # run the task in an asynchronous sub-shell
      CUDA_VISIBLE_DEVICES=$TOKEN run_workflow $WORKDIR

      # put back the token
      printf '%s,' $TOKEN >&3
    )&
  done

  # wait for all tasks to complete
  wait
}

# Make validation plots, based on the DQM output of step4 and makeTrackValidationPlots.py
# and upload them to the EOS www area.
#
# Usage:
#   make_validation_plots REFERENCE_RELEASE [[RELEASE ...] TARGET_RELEASE]
#
function make_validation_plots() {
  [ "$1" ] || return 1
  local DIRNAME="${!#}"
  local REFERENCE_RELEASE="$1"
  local -a RELEASES=("$@")
  shift
  local -a TESTING_RELEASES=($@)
  cd $BASE/$DIRNAME
  eval $(scram runtime -sh)

  report "### \`makeTrackValidationPlots.py\` plots"

  local SAMPLE
  for SAMPLE in $SAMPLES; do
    local DATASET=${!SAMPLE}
    report "#### $DATASET"
    local WORKDIR=$(echo $DATASET | cut -d/ -f 2-3 --output-delimiter=-)
    mkdir -p $BASE/plots/$WORKDIR
    cd $BASE/plots/$WORKDIR

    # reference release and workflow
    local FILE=$BASE/$REFERENCE_RELEASE/run/$WORKDIR/$REFERENCE_WORKFLOW/$DQMFILE
    [ -f $FILE ] && ln -s $FILE ${REFERENCE_RELEASE}-${REFERENCE_WORKFLOW}.root

    # development releases and workflows
    local RELEASE
    for RELEASE in ${TESTING_RELEASES[@]}; do
      local WORKFLOW
      for WORKFLOW in $WORKFLOWS; do
        local FILE=$BASE/$RELEASE/run/$WORKDIR/$WORKFLOW/$DQMFILE
        [ -f $FILE ] && ln -s $FILE ${RELEASE}-${WORKFLOW}.root
      done
    done

    # validation of all workflows across all releases
    local WORKFLOW
    for WORKFLOW in $WORKFLOWS; do
      mkdir -p $LOCAL_DIR/$JOBID/$WORKDIR/$WORKFLOW
      if [ "$WORKFLOW" == "$REFERENCE_WORKFLOW" ]; then
        # reference workflow
        makeTrackValidationPlots.py \
          --extended \
          --html-sample $DATASET \
          --html-validation-name $DATASET \
          --outputDir $LOCAL_DIR/$JOBID/$WORKDIR/$REFERENCE_WORKFLOW \
          ${RELEASES[@]/%/-${REFERENCE_WORKFLOW}.root}
        report "  - tracking validation [plots]($UPLOAD_URL/$JOBID/$WORKDIR/$WORKFLOW/index.html) and [summary]($UPLOAD_URL/$JOBID/$WORKDIR/$WORKFLOW/plots_summary.html) for workflow $WORKFLOW"
      else
        # other workflows
        local FILES=""
        local RELEASE
        for RELEASE in ${TESTING_RELEASES[@]}; do
          [ -f ${RELEASE}-${WORKFLOW}.root ] && FILES="$FILES ${RELEASE}-${WORKFLOW}.root"
        done
        if [ "$FILES" ]; then
          makeTrackValidationPlots.py \
            --extended \
            --html-sample $DATASET \
            --html-validation-name $DATASET \
            --outputDir $LOCAL_DIR/$JOBID/$WORKDIR/$WORKFLOW \
            ${REFERENCE_RELEASE}-${REFERENCE_WORKFLOW}.root \
            ${TESTING_RELEASES[0]}-${REFERENCE_WORKFLOW}.root \
            $FILES
          report "  - tracking validation [plots]($UPLOAD_URL/$JOBID/$WORKDIR/$WORKFLOW/index.html) and [summary]($UPLOAD_URL/$JOBID/$WORKDIR/$WORKFLOW/plots_summary.html) for workflow $WORKFLOW"
        else
          report "  - :warning: tracking validation plots and summary for workflow $WORKFLOW are **missing**"
        fi
      fi
    done
    report
  done
}

# If the source file exists, dereference any symlinks amd copy it preserving mode, ownership, and timestamps
#
# Usage
#  copy_if_exists SRC DST
#
function copy_if_exists() {
  [ -f "$1" ] && cp -p -L "$1" "$2" || true
}

# Upload the output of a validation job
#
# Usage
#  upload_artefacts RELEASE WORKDIR WORKFLOW NAME
#
function upload_artefacts() {
  local RELEASE=$1
  local WORKDIR=$2
  local WORKFLOW=$3
  local CWD=$BASE/$RELEASE/run/$WORKDIR/$WORKFLOW
  report "  - $RELEASE release, workflow $WORKFLOW"

  # check the artefacts to look for and upload
  NAMES=
  [ -f $CWD/step3.py ]   && NAMES="$NAMES step3"
  [ -f $CWD/profile.py ] && NAMES="$NAMES profile"

  for NAME in $NAMES; do
    local FILE=$CWD/$NAME
    local PART=$JOBID/$WORKDIR/$RELEASE-$WORKFLOW-$NAME
    # upload the python configuration file, log, and nvprof results (if they exist)
    copy_if_exists ${FILE}.py      $LOCAL_DIR/${PART}.py
    copy_if_exists ${FILE}.log     $LOCAL_DIR/${PART}.log
    copy_if_exists ${FILE}.nvvp    $LOCAL_DIR/${PART}.nvvp
    copy_if_exists ${FILE}.profile $LOCAL_DIR/${PART}.profile
    if ! [ -f ${FILE}.log ]; then
      # if there is no log file, the workflow most likely did not run at all
      report "      - :x: [${NAME}.py]($UPLOAD_URL/${PART}.py): log, profile and summary are **missing**, see the full log for more information"
      continue
    fi
    local FLAG
    # check if the job was successful
    if [ -f ${FILE}.done ]; then
      FLAG=":heavy_check_mark:"
    else
      FLAG=":x:"
    fi 
    # check for both profile and summary
    if [ -f ${FILE}.nvvp ] && [ -f ${FILE}.profile ]; then
      report "      - ${FLAG} [${NAME}.py]($UPLOAD_URL/${PART}.py): [log]($UPLOAD_URL/${PART}.log), [visual profile]($UPLOAD_URL/${PART}.nvvp) and [summary]($UPLOAD_URL/${PART}.profile)"
    elif [ -f ${FILE}.nvvp ]; then
      report "      - ${FLAG} [${NAME}.py]($UPLOAD_URL/${PART}.py): [log]($UPLOAD_URL/${PART}.log) and [visual profile]($UPLOAD_URL/${PART}.nvvp)"
    elif [ -f ${FILE}.profile ]; then
      report "      - ${FLAG} [${NAME}.py]($UPLOAD_URL/${PART}.py): [log]($UPLOAD_URL/${PART}.log) and [summary]($UPLOAD_URL/${PART}.profile)"
    else
      report "      - ${FLAG} [${NAME}.py]($UPLOAD_URL/${PART}.py): [log]($UPLOAD_URL/${PART}.log)"
    fi
    unset FLAG
  done

  # check for cuda-memcheck
  if [ -f $CWD/memcheck.py ]; then
    local PART=$JOBID/$WORKDIR/$RELEASE-$WORKFLOW
    # cuda-memcheck --tool initcheck
    copy_if_exists $CWD/initcheck.out $LOCAL_DIR/$PART-initcheck.out
    copy_if_exists $CWD/initcheck.log $LOCAL_DIR/$PART-initcheck.log
    if [ -f $CWD/cuda-initcheck.done ]; then
      report "      - :heavy_check_mark: \`cuda-memcheck --tool initcheck $SYNCCHECK_OPTS\` ([report]($UPLOAD_URL/$PART-initcheck.out), [log]($UPLOAD_URL/$PART-initcheck.log)) did not find any errors"
    elif [ -f $CWD/cuda-initcheck.fail ]; then
      local ERRORS="**some errors**"
      [ -f $CWD/initcheck.out ] && ERRORS="**$(echo $(tail -n1 $CWD/initcheck.out | cut -d: -f2 | sed -e's/========= No CUDA-MEMCHECK results found/no CUDA-MEMCHECK results/'))**"
      report "      - :x: \`cuda-memcheck --tool initcheck $SYNCCHECK_OPTS\` ([report]($UPLOAD_URL/$PART-initcheck.out), [log]($UPLOAD_URL/$PART-initcheck.log)) found $ERRORS"
      unset ERRORS
    else
      report "      - :warning: \`cuda-memcheck --tool initcheck $SYNCCHECK_OPTS\` did not run"
    fi
    # cuda-memcheck --tool memcheck
    copy_if_exists $CWD/memcheck.out $LOCAL_DIR/$PART-memcheck.out
    copy_if_exists $CWD/memcheck.log $LOCAL_DIR/$PART-memcheck.log
    if [ -f $CWD/cuda-memcheck.done ]; then
      report "      - :heavy_check_mark: \`cuda-memcheck --tool memcheck $MEMCHECK_OPTS\` ([report]($UPLOAD_URL/$PART-memcheck.out), [log]($UPLOAD_URL/$PART-memcheck.log)) did not find any errors"
    elif [ -f $CWD/cuda-memcheck.fail ]; then
      local ERRORS="**some errors**"
      [ -f $CWD/memcheck.out ] && ERRORS="**$(echo $(tail -n1 $CWD/memcheck.out | cut -d: -f2 | sed -e's/========= No CUDA-MEMCHECK results found/no CUDA-MEMCHECK results/'))**"
      report "      - :x: \`cuda-memcheck --tool memcheck $MEMCHECK_OPTS\` ([report]($UPLOAD_URL/$PART-memcheck.out), [log]($UPLOAD_URL/$PART-memcheck.log)) found $ERRORS"
      unset ERRORS
    else
      report "      - :warning: \`cuda-memcheck --tool memcheck $MEMCHECK_OPTS\` did not run"
    fi
    # cuda-memcheck --tool synccheck
    copy_if_exists $CWD/synccheck.out $LOCAL_DIR/$PART-synccheck.out
    copy_if_exists $CWD/synccheck.log $LOCAL_DIR/$PART-synccheck.log
    if [ -f $CWD/cuda-synccheck.done ]; then
      report "      - :heavy_check_mark: \`cuda-memcheck --tool synccheck $SYNCCHECK_OPTS\` ([report]($UPLOAD_URL/$PART-synccheck.out), [log]($UPLOAD_URL/$PART-synccheck.log)) did not find any errors"
    elif [ -f $CWD/cuda-synccheck.fail ]; then
      local ERRORS="**some errors**"
      [ -f $CWD/synccheck.out ] && ERRORS="**$(echo $(tail -n1 $CWD/synccheck.out | cut -d: -f2 | sed -e's/========= No CUDA-MEMCHECK results found/no CUDA-MEMCHECK results/'))**"
      report "      - :x: \`cuda-memcheck --tool synccheck $SYNCCHECK_OPTS\` ([report]($UPLOAD_URL/$PART-synccheck.out), [log]($UPLOAD_URL/$PART-synccheck.log)) found $ERRORS"
      unset ERRORS
    else
      report "      - :warning: \`cuda-memcheck --tool synccheck $SYNCCHECK_OPTS\` did not run"
    fi
  fi
}

# Upload nvprof profiles
#
# Usage:
#   upload_profiles REFERENCE_RELEASE [[RELEASE ...] TARGET_RELEASE]
#
function upload_profiles() {
  [ "$1" ] || return 1
  local REFERENCE_RELEASE="$1"
  local -a RELEASES=("$@")
  shift
  local -a TESTING_RELEASES=($@)

  report "### logs and \`nvprof\`/\`nvvp\` profiles"

  local SAMPLE
  for SAMPLE in $SAMPLES; do
    local DATASET=${!SAMPLE}
    report "#### $DATASET"
    local WORKDIR=$(echo $DATASET | cut -d/ -f 2-3 --output-delimiter=-)

    # reference release and workflow
    upload_artefacts $REFERENCE_RELEASE $WORKDIR $REFERENCE_WORKFLOW

    # development releases and workflows
    local RELEASE
    for RELEASE in ${TESTING_RELEASES[@]}; do
      local WORKFLOW
      for WORKFLOW in $WORKFLOWS; do
        upload_artefacts $RELEASE $WORKDIR $WORKFLOW
      done
    done
    report
  done
}

# Upload the log file
#
# Usage:
#   upload_log_files REFERENCE_RELEASE [[RELEASE ...] TARGET_RELEASE]
#
# Note: the releases are used to build the hash of the upload area
#
function upload_log_files() {
  [ "$1" ] || return 1
  local -a RELEASES=("$@")

  cp $BASE/log $LOCAL_DIR/$JOBID/log
  report "## Logs"
  report "The full log is available at $UPLOAD_URL/$JOBID/log ."
}

# main
echo > $REPORT

# upload the report to the last PR given on the command line
for ISSUE_NUMBER in "$@"; do true; done

# if we can edit the comment after posting it, create an empty comment as a starting point
COMMENT_ID=$(can_post_comment $ISSUE_NUMBER && $EDIT_COMMENT && upload_report $ISSUE_NUMBER) || true

# set up the reference release
report "## Validation summary"
setup_release "reference" CMSSW_11_0_0_pre7
report "Reference release [CMSSW_11_0_0_pre7](https://github.com/cms-sw/cmssw/tree/CMSSW_11_0_0_pre7) at $(< $BASE/reference/hash)"
build_matrix "reference" "$REFERENCE_WORKFLOW"
DIRECTORIES="reference"
upload_report $ISSUE_NUMBER $COMMENT_ID

# set up the current development branch
setup_development_release "development" CMSSW_11_0_0_pre7_Patatrack CMSSW_11_0_X_Patatrack $REPOSITORY
report "Development branch [CMSSW_11_0_X_Patatrack](https://github.com/$REPOSITORY/cmssw/tree/CMSSW_11_0_X_Patatrack) at $(< $BASE/development/hash)"
build_matrix "development" "$WORKFLOWS"
build_data_matrix "development" "$DATA_WORKFLOWS"
DIRECTORIES+=" development"
upload_report $ISSUE_NUMBER $COMMENT_ID

# set up the development branch plus the PR(s) to be tested
if [ "$*" ]; then
  clone_release "development" "testing"
  report "Testing PRs:"
  for PR in "$@"; do
    git cms-merge-topic "$REPOSITORY:$PR"
    echo $PR >> $BASE/testing/PRs
    report "  - #$PR at $(git rev-parse --short=12 "$REPOSITORY/refs/pull/$PR/head")"
  done
  git rev-parse --short=12 HEAD > ../hash
  USER_CXXFLAGS="-g -rdynamic" USER_CUDA_FLAGS="-g -lineinfo" scram b -j
  build_matrix "testing" "$WORKFLOWS"
  build_data_matrix "testing" "$DATA_WORKFLOWS"
  DIRECTORIES+=" testing"
fi
report
upload_report $ISSUE_NUMBER $COMMENT_ID

# compute a unique hash for this validation run
JOBID=$({ echo $SCRIPTHASH; cat $(apply_and_glob "$BASE/%/hash" $DIRECTORIES); } | sha1sum | cut -d' ' -f1)
echo $JOBID > $BASE/jobid

# run the workflows
run_workflows_in_parallel $DIRECTORIES
upload_report $ISSUE_NUMBER $COMMENT_ID
# make validation plots
make_validation_plots $DIRECTORIES
upload_report $ISSUE_NUMBER $COMMENT_ID
# upload DQM plots to the GUI
#upload_dqm_plots $DIRECTORIES
#upload_report $ISSUE_NUMBER $COMMENT_ID
# upload nvprof profiles
upload_profiles $DIRECTORIES
upload_report $ISSUE_NUMBER $COMMENT_ID

# restore the original descriptors, close and upload the log files
exec 1>&3- 2>&4-
upload_log_files $DIRECTORIES

echo "This report can be found at $REPORT:"
echo
cat $REPORT

# post the report to GitHub
upload_final_report $ISSUE_NUMBER $COMMENT_ID

# suggest to upload the plots and reports
if ! hostname | grep -q '\.cern\.ch'; then
  echo "Please upload the plots and reports with:"
  echo "  rsync -arvzz $LOCAL_DIR/$JOBID lxplus.cern.ch:$UPLOAD_DIR/"
fi
