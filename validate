#! /bin/bash -e

# Script for testing one or more pull requests against a reference release and an intermediate development release
#
# Usage:
#   validate [PR ...]
#
# Note: this script relies on `visDQMUpload` and `visDQMUtils.py` being available in the same directory.
# If they are missing they are automatically downloaded from https://github.com/rovere/dqmgui/ .

# Create a temporay working directory
BASE=$(mktemp -d -p $PWD run.XXXXXXXXXX)
[ -d $BASE ] || exit 1
REPORT=$BASE/report.md

# save the original file descriptors, then redirect all output and errors to a log file
exec 3>&1 4>&2
exec &> $BASE/log

# Local configuration - should go before the others
source local.sh

# CMSSW configuration
source cmssw.sh

# DQM configuration
source dqm.sh

# GitHub-related configuration
source github.sh

# Input samples configuration
source input.sh

# Hash of this script and its configuration
SCRIPTHASH=$(cat $(dirname ${BASH_SOURCE[0]})/config*.sh ${BASH_SOURCE[0]} | sha1sum | cut -d' ' -f1)

# cuda-memcheck tools options
INITCHECK_OPTS="--track-unused-memory no"
MEMCHECK_OPTS="--leak-check full --report-api-errors all"
SYNCCHECK_OPTS=""

function report() {
  echo "$@" >> $REPORT
}

function apply() {
  PATTERN="$1"; shift
    for ARG; do echo $PATTERN | sed -e"s/%/$ARG/g"; done
}

function apply_and_glob() {
  echo $(apply "$@")
}

function has_profiling() {
  local WORKFLOW=$1
  echo "$PROFILING" | grep -q -w "$WORKFLOW"
}

function has_memcheck() {
  local WORKFLOW=$1
  echo "$MEMCHECKS" | grep -q -w "$WORKFLOW"
}

function build_matrix() {
  local DIRNAME="$1"
  shift
  local WORKFLOWS="$@"
  local SAMPLE DATASET WORKDIR CACHE_PATH CACHE_FILE INPUT MY_GLOBALTAG MY_NUMEVENTS WORKFLOW STEP3 STEP4
  # create the matrix-like workflows for the various samples
  cd $BASE/$DIRNAME
  eval $(scram runtime -sh)
  for SAMPLE in $SAMPLES; do
    DATASET=${!SAMPLE}
    WORKDIR=$(echo $DATASET | cut -d/ -f 2-3 --output-delimiter=-)
    CACHE_PATH=$(eval echo \$$(echo $SAMPLE)_CACHE_PATH)
    CACHE_FILE=$(eval echo \$$(echo $SAMPLE)_CACHE_FILE)
    if [ "$CACHE_PATH" ] && [ "$CACHE_FILE" ]; then
      INPUT="--dirin=$CACHE_PATH --filein $CACHE_FILE"
    else
      INPUT="--dasquery 'file dataset=$DATASET'"
    fi
    # customise the global tag and number of events by dataset, or use the default values
    MY_GLOBALTAG=$(eval echo \$$(echo $SAMPLE)_GLOBALTAG)
    MY_NUMEVENTS=$(eval echo \$$(echo $SAMPLE)_NUMEVENTS)
    echo "# prepare to run on ${MY_NUMEVENTS:=$NUMEVENTS} events on $DATASET with ${MY_GLOBALTAG:=$GLOBALTAG} conditions"
    mkdir -p $CMSSW_BASE/run/$WORKDIR
    cd $CMSSW_BASE/run/$WORKDIR
    for WORKFLOW in $WORKFLOWS; do
      # check the the workflow actually exists in the release
      runTheMatrix.py -n -e -l $WORKFLOW | grep -q ^$WORKFLOW || continue
      mkdir -p $WORKFLOW
      cd $WORKFLOW
      # extract step3 and step4 commands
      STEP3="$(runTheMatrix.py -n -e -l $WORKFLOW | grep 'cmsDriver.py step3' | cut -d: -f2- | sed -e"s/^ *//" -e"s/ \+--conditions *[^ ]\+/ --conditions $MY_GLOBALTAG/" -e"s/ \+-n *[^ ]\+/ -n $MY_NUMEVENTS/") --fileout file:step3.root"
      STEP4="$(runTheMatrix.py -n -e -l $WORKFLOW | grep 'cmsDriver.py step4' | cut -d: -f2- | sed -e"s/^ *//" -e"s/ \+--conditions *[^ ]\+/ --conditions $MY_GLOBALTAG/" -e"s/ \+-n *[^ ]\+/ -n $MY_NUMEVENTS/") --filein file:step3_inDQM.root"
      echo "# prepare workflow $WORKFLOW"
      $STEP3 $INPUT --no_exec --python_filename=step3.py
      $STEP4        --no_exec --python_filename=step4.py
      # add the NVProfilerService to step3
      sed -i step3.py -e '/\# End of customisation functions/i \
# Mark CMSSW transitions and modules in the nvprof profile\
from FWCore.ParameterSet.Utilities import moduleLabelsInSequences\
process.NVProfilerService = cms.Service("NVProfilerService",\
    highlightModules = cms.untracked.vstring( moduleLabelsInSequences(process.reconstruction_step) ),\
    showModulePrefetching = cms.untracked.bool( False )\
)\
\
# Show CUDAService messages\
process.MessageLogger.categories.append("CUDAService")\
'
      echo >> step3.py
      echo "# Configure multithreading" >> step3.py
      echo "process.options.numberOfThreads = cms.untracked.uint32( $THREADS )" >> step3.py
      echo "process.options.numberOfStreams = cms.untracked.uint32( $STREAMS )" >> step3.py

      local CUSTOMISE=RecoPixelVertexing/Configuration/customizePixelTracksForProfiling
      if has_profiling $WORKFLOW && ( [ -f $CMSSW_RELEASE_BASE/python/${CUSTOMISE}.py ] || [ -f $CMSSW_BASE/python/${CUSTOMISE}.py ] ); then
        # mark the workflow to run the profiling job
        touch .has_profiling
        # create a profiling workflow
        $STEP3 $INPUT --no_exec --customise ${CUSTOMISE}.customizePixelTracksForProfiling --python_filename=profile.py
        # add the NVProfilerService to profile
        sed -i profile.py -e '/\# End of customisation functions/i \
# Mark CMSSW transitions and modules in the nvprof profile\
from FWCore.ParameterSet.Utilities import moduleLabelsInSequences\
process.NVProfilerService = cms.Service("NVProfilerService",\
    highlightModules = cms.untracked.vstring( moduleLabelsInSequences(process.reconstruction_step) ),\
    showModulePrefetching = cms.untracked.bool( False )\
)\
\
# Show CUDAService messages\
process.MessageLogger.categories.append("CUDAService")\
'
        echo >> profile.py
        echo "# Configure multithreading" >> profile.py
        echo "process.options.numberOfThreads = cms.untracked.uint32( $THREADS )" >> profile.py
        echo "process.options.numberOfStreams = cms.untracked.uint32( $STREAMS )" >> profile.py
      fi

      if has_memcheck $WORKFLOW; then
        # prepare the workflow to run the various cuda-memcheck checks
        cp step3.py memcheck.py
        echo >> memcheck.py
        echo '# limit he number of events for cuda-memcheck' >> memcheck.py
        echo 'process.maxEvents.input = 10' >> memcheck.py
      fi

      cd ..
    done
    echo
  done
}

function run_workflow() {
  local WORKDIR="$1"
  local STEP3_SUCCESS

  cd $BASE/$WORKDIR
  echo "# at $WORKDIR"
  eval $(scram runtime -sh)

  # run step 3
  echo -n "# running step3... "
  if nvprof -f -o step3.nvvp -s --log-file step3.profile -- cmsRun step3.py >& step3.log; then
    STEP3_SUCCESS=true
    echo "done"
  else
    STEP3_SUCCESS=false
    echo "failed"
    tail step3.log
  fi

  # do not attempt to run step4 or profile if step3 failed
  if $STEP3_SUCCESS; then
    # run step 4
    echo -n "# running step4... "
    if cmsRun step4.py >& step4.log; then
      echo "done"
    else
      echo "failed"
      tail step4.log
    fi

    # (optional) run profile
    if [ -f .has_profiling ]; then
      echo -n "# running profile... "
      if nvprof -f -o profile.nvvp -s --log-file profile.profile -- cmsRun profile.py >& profile.log; then
        echo "done"
      else
        echo "failed"
        tail profile.log
      fi
    fi
  fi

  # (optional) run cuda-memcheck
  if [ -f memcheck.py ]; then
    # initcheck
    echo -n "# running cuda-memcheck --tool initcheck... "
    if cuda-memcheck --tool initcheck --error-exitcode 127 $INITCHECK_OPTS --log-file cuda-initcheck.log -- cmsRun step3.py >& step3-initcheck.log; then
      [ -f step3-initcheck.log ] && cat step3-initcheck.log | c++filt -i > demangled && mv demangled step3-initcheck.log
      echo "done"
      touch cuda-initcheck.done
    else
      echo "failed"
      tail cuda-initcheck.log
      touch cuda-initcheck.fail
    fi
    # memcheck
    echo -n "# running cuda-memcheck --tool memcheck... "
    if cuda-memcheck --tool memcheck --error-exitcode 127 $MEMCHECK_OPTS --log-file cuda-memcheck.log -- cmsRun step3.py >& step3-memcheck.log; then
      [ -f step3-memcheck.log ] && cat step3-memcheck.log | c++filt -i > demangled && mv demangled step3-memcheck.log
      echo "done"
      touch cuda-memcheck.done
    else
      echo "failed"
      tail cuda-memcheck.log
      touch cuda-memcheck.fail
    fi
    # synccheck
    echo -n "# running cuda-memcheck --tool synccheck... "
    if cuda-memcheck --tool synccheck --error-exitcode 127 $SYNCCHECK_OPTS --log-file cuda-synccheck.log -- cmsRun step3.py >& step3-synccheck.log; then
      [ -f step3-synccheck.log ] && cat step3-synccheck.log | c++filt -i > demangled && mv demangled step3-synccheck.log
      echo "done"
      touch cuda-synccheck.done
    else
      echo "failed"
      tail cuda-synccheck.log
      touch cuda-synccheck.fail
    fi
  fi

  cd $BASE
}

function run_workflows() {
  cd $BASE

  local WORKDIR
  for WORKDIR in $(apply_and_glob "%/run/*/*/" "$@"); do
    run_workflow $WORKDIR
  done
}

function run_workflows_in_parallel() {
  local MAXJOBS=$(($1))
  cd $BASE

  local WORKDIR
  for WORKDIR in $(apply_and_glob "%/run/*/*/" "$@"); do
    # run up to MAXJOBS in parallel
    while (( $(jobs | wc -l) >= $MAXJOBS )); do sleep 1; done
    run_workflow $WORKDIR &
  done
  wait
}

# Make validation plots, based on the DQM output of step4 and makeTrackValidationPlots.py
# and upload them to the EOS www area.
#
# Usage:
#   make_validation_plots REFERENCE_RELEASE [[RELEASE ...] TARGET_RELEASE]
#
function make_validation_plots() {
  [ "$1" ] || return 1
  local DIRNAME="${!#}"
  local REFERENCE_RELEASE="$1"
  local -a RELEASES=("$@")
  shift
  local -a TESTING_RELEASES=($@)
  cd $BASE/$DIRNAME
  eval $(scram runtime -sh)

  report "### \`makeTrackValidationPlots.py\` plots"

  local SAMPLE
  for SAMPLE in $SAMPLES; do
    local DATASET=${!SAMPLE}
    report "#### $DATASET"
    local WORKDIR=$(echo $DATASET | cut -d/ -f 2-3 --output-delimiter=-)
    mkdir -p $BASE/plots/$WORKDIR
    cd $BASE/plots/$WORKDIR

    # reference release and workflow
    local FILE=$BASE/$REFERENCE_RELEASE/run/$WORKDIR/$REFERENCE_WORKFLOW/$DQMFILE
    [ -f $FILE ] && ln -s $FILE ${REFERENCE_RELEASE}-${REFERENCE_WORKFLOW}.root

    # development releases and workflows
    local RELEASE
    for RELEASE in ${TESTING_RELEASES[@]}; do
      local WORKFLOW
      for WORKFLOW in $WORKFLOWS; do
        local FILE=$BASE/$RELEASE/run/$WORKDIR/$WORKFLOW/$DQMFILE
        [ -f $FILE ] && ln -s $FILE ${RELEASE}-${WORKFLOW}.root
      done
    done

    # validation of all workflows across all releases
    local WORKFLOW
    for WORKFLOW in $WORKFLOWS; do
      mkdir -p $UPLOAD_DIR/$JOBID/$WORKDIR/$WORKFLOW
      if [ "$WORKFLOW" == "$REFERENCE_WORKFLOW" ]; then
        # reference workflow
        makeTrackValidationPlots.py \
          --extended \
          --html-sample $DATASET \
          --html-validation-name $DATASET \
          --outputDir $UPLOAD_DIR/$JOBID/$WORKDIR/$REFERENCE_WORKFLOW \
          ${RELEASES[@]/%/-${REFERENCE_WORKFLOW}.root}
        report "  - tracking validation [plots]($UPLOAD_URL/$JOBID/$WORKDIR/$WORKFLOW/index.html) and [summary]($UPLOAD_URL/$JOBID/$WORKDIR/$WORKFLOW/plots_summary.html) for workflow $WORKFLOW"
      else
        # other workflows
        local FILES=""
        local RELEASE
        for RELEASE in ${TESTING_RELEASES[@]}; do
          [ -f ${RELEASE}-${WORKFLOW}.root ] && FILES="$FILES ${RELEASE}-${WORKFLOW}.root"
        done
        if [ "$FILES" ]; then
          makeTrackValidationPlots.py \
            --extended \
            --html-sample $DATASET \
            --html-validation-name $DATASET \
            --outputDir $UPLOAD_DIR/$JOBID/$WORKDIR/$WORKFLOW \
            ${REFERENCE_RELEASE}-${REFERENCE_WORKFLOW}.root \
            ${TESTING_RELEASES[0]}-${REFERENCE_WORKFLOW}.root \
            $FILES
          report "  - tracking validation [plots]($UPLOAD_URL/$JOBID/$WORKDIR/$WORKFLOW/index.html) and [summary]($UPLOAD_URL/$JOBID/$WORKDIR/$WORKFLOW/plots_summary.html) for workflow $WORKFLOW"
        else
          report "  - :warning: tracking validation plots and summary for workflow $WORKFLOW are **missing**"
        fi
      fi
    done
    report
  done
}

# If the source file exists, dereference any symlinks amd copy it preserving mode, ownership, and timestamps
#
# Usage
#  copy_if_exists SRC DST
#
function copy_if_exists() {
  [ -f "$1" ] && cp -p -L "$1" "$2" || true
}

# Upload the output of a validation job
#
# Usage
#  upload_artefacts RELEASE WORKDIR WORKFLOW NAME
#
function upload_artefacts() {
  local RELEASE=$1
  local WORKDIR=$2
  local WORKFLOW=$3
  local CWD=$BASE/$RELEASE/run/$WORKDIR/$WORKFLOW
  report "  - $RELEASE release, workflow $WORKFLOW"

  # check the artefacts to look for and upload
  NAMES=step3
  [ -f $CWD/.has_profiling ] && NAMES="$NAMES profile"

  for NAME in $NAMES; do
    local FILE=$CWD/$NAME
    local PART=$JOBID/$WORKDIR/$RELEASE-$WORKFLOW-$NAME
    # upload the python configuration file, log, and nvprof results (if they exist)
    copy_if_exists ${FILE}.py      $UPLOAD_DIR/${PART}.py
    copy_if_exists ${FILE}.log     $UPLOAD_DIR/${PART}.log
    copy_if_exists ${FILE}.nvvp    $UPLOAD_DIR/${PART}.nvvp
    copy_if_exists ${FILE}.profile $UPLOAD_DIR/${PART}.profile
    # update the report
    if ! [ -f ${FILE}.py ]; then
      # the workflow has not been created
      report "      - ${NAME}.py: the python configuration was not created, see the full log for more information"
      continue
    fi
    if ! [ -f ${FILE}.log ]; then
      # if there is no log file, the workflow most likely did not run at all
      report "      - :warning: [${NAME}.py]($UPLOAD_URL/${PART}.py): log, profile and summary are **missing**, see the full log for more information"
      continue
    fi
    # check for both profile and summary
    if [ -f ${FILE}.nvvp ] && [ -f ${FILE}.profile ]; then
      report "      - [${NAME}.py]($UPLOAD_URL/${PART}.py): [log]($UPLOAD_URL/${PART}.log), [visual profile]($UPLOAD_URL/${PART}.nvvp) and [summary]($UPLOAD_URL/${PART}.profile)"
    elif [ -f ${FILE}.nvvp ]; then
      report "      - [${NAME}.py]($UPLOAD_URL/${PART}.py): [log]($UPLOAD_URL/${PART}.log) and [visual profile]($UPLOAD_URL/${PART}.nvvp)"
    elif [ -f ${FILE}.profile ]; then
      report "      - [${NAME}.py]($UPLOAD_URL/${PART}.py): [log]($UPLOAD_URL/${PART}.log) and [summary]($UPLOAD_URL/${PART}.profile)"
    else
      report "      - :warning: [${NAME}.py]($UPLOAD_URL/${PART}.py): [log]($UPLOAD_URL/${PART}.log); the visual profile and summary are **missing**"
    fi
  done

  # check for cuda-memcheck
  if [ -f $CWD/memcheck.py ]; then
    local PART=$JOBID/$WORKDIR/$RELEASE-$WORKFLOW
    # cuda-memcheck --tool initcheck
    copy_if_exists $CWD/cuda-initcheck.log  $UPLOAD_DIR/$PART-cuda-initcheck.log
    copy_if_exists $CWD/step3-initcheck.log $UPLOAD_DIR/$PART-step3-initcheck.log
    local ERRORS="**some errors**"
    [ -f $CWD/cuda-initcheck.log ] && ERRORS="**$(echo $(tail -n1 $CWD/cuda-initcheck.log | cut -d: -f2 | sed -e's/========= No CUDA-MEMCHECK results found/no CUDA-MEMCHECK results/'))**"
    if [ -f $CWD/cuda-initcheck.done ]; then
      report "      - :heavy_check_mark: \`cuda-memcheck --tool initcheck $INITCHECK_OPTS\` ([report]($UPLOAD_URL/$PART-cuda-initcheck.log), [log]($UPLOAD_URL/$PART-step3-initcheck.log)) did not find any errors"
    elif [ -f $CWD/cuda-initcheck.fail ]; then
      report "      - :x: \`cuda-memcheck --tool initcheck $INITCHECK_OPTS\` ([report]($UPLOAD_URL/$PART-cuda-initcheck.log), [log]($UPLOAD_URL/$PART-step3-initcheck.log)) found $ERRORS"
    else
      report "      - :warning: \`cuda-memcheck --tool initcheck $INITCHECK_OPTS\` did not run"
    fi
    # cuda-memcheck --tool memcheck
    copy_if_exists $CWD/cuda-memcheck.log  $UPLOAD_DIR/$PART-cuda-memcheck.log
    copy_if_exists $CWD/step3-memcheck.log $UPLOAD_DIR/$PART-step3-memcheck.log
    local ERRORS="**some errors**"
    [ -f $CWD/cuda-memcheck.log ] && ERRORS="**$(echo $(tail -n1 $CWD/cuda-memcheck.log | cut -d: -f2 | sed -e's/========= No CUDA-MEMCHECK results found/no CUDA-MEMCHECK results/'))**"
    if [ -f $CWD/cuda-memcheck.done ]; then
      report "      - :heavy_check_mark: \`cuda-memcheck --tool memcheck $MEMCHECK_OPTS\` ([report]($UPLOAD_URL/$PART-cuda-memcheck.log), [log]($UPLOAD_URL/$PART-step3-memcheck.log)) did not find any errors"
    elif [ -f $CWD/cuda-memcheck.fail ]; then
      report "      - :x: \`cuda-memcheck --tool memcheck $MEMCHECK_OPTS\` ([report]($UPLOAD_URL/$PART-cuda-memcheck.log), [log]($UPLOAD_URL/$PART-step3-memcheck.log)) found $ERRORS"
    else
      report "      - :warning: \`cuda-memcheck --tool memcheck $MEMCHECK_OPTS\` did not run"
    fi
    # cuda-memcheck --tool synccheck
    copy_if_exists $CWD/cuda-synccheck.log  $UPLOAD_DIR/$PART-cuda-synccheck.log
    copy_if_exists $CWD/step3-synccheck.log $UPLOAD_DIR/$PART-step3-synccheck.log
    local ERRORS="**some errors**"
    [ -f $CWD/cuda-synccheck.log ] && ERRORS="**$(echo $(tail -n1 $CWD/cuda-synccheck.log | cut -d: -f2 | sed -e's/========= No CUDA-MEMCHECK results found/no CUDA-MEMCHECK results/'))**"
    if [ -f $CWD/cuda-synccheck.done ]; then
      report "      - :heavy_check_mark: \`cuda-memcheck --tool synccheck $SYNCCHECK_OPTS\` ([report]($UPLOAD_URL/$PART-cuda-synccheck.log), [log]($UPLOAD_URL/$PART-step3-synccheck.log)) did not find any errors"
    elif [ -f $CWD/cuda-synccheck.fail ]; then
      report "      - :x: \`cuda-memcheck --tool synccheck $SYNCCHECK_OPTS\` ([report]($UPLOAD_URL/$PART-cuda-synccheck.log), [log]($UPLOAD_URL/$PART-step3-synccheck.log)) found $ERRORS"
    else
      report "      - :warning: \`cuda-memcheck --tool synccheck $SYNCCHECK_OPTS\` did not run"
    fi
  fi
}

# Upload nvprof profiles
#
# Usage:
#   upload_profiles REFERENCE_RELEASE [[RELEASE ...] TARGET_RELEASE]
#
function upload_profiles() {
  [ "$1" ] || return 1
  local REFERENCE_RELEASE="$1"
  local -a RELEASES=("$@")
  shift
  local -a TESTING_RELEASES=($@)

  report "### logs and \`nvprof\`/\`nvvp\` profiles"

  local SAMPLE
  for SAMPLE in $SAMPLES; do
    local DATASET=${!SAMPLE}
    report "#### $DATASET"
    local WORKDIR=$(echo $DATASET | cut -d/ -f 2-3 --output-delimiter=-)

    # reference release and workflow
    upload_artefacts $REFERENCE_RELEASE $WORKDIR $REFERENCE_WORKFLOW

    # development releases and workflows
    local RELEASE
    for RELEASE in ${TESTING_RELEASES[@]}; do
      local WORKFLOW
      for WORKFLOW in $WORKFLOWS; do
        upload_artefacts $RELEASE $WORKDIR $WORKFLOW
      done
    done
    report
  done
}

# Upload the log file
#
# Usage:
#   upload_log_files REFERENCE_RELEASE [[RELEASE ...] TARGET_RELEASE]
#
# Note: the releases are used to build the hash of the upload area
#
function upload_log_files() {
  [ "$1" ] || return 1
  local -a RELEASES=("$@")

  cp $BASE/log $UPLOAD_DIR/$JOBID/log
  report "### Logs"
  report "The full log is available at $UPLOAD_URL/$JOBID/log ."
}

# main
echo > $REPORT

# upload the report to the last PR given on the command line
for ISSUE_NUMBER in "$@"; do true; done

# if we can edit the comment after posting it, create an empty comment as a starting point
COMMENT_ID=$(can_post_comment $ISSUE_NUMBER && $EDIT_COMMENT && upload_report $ISSUE_NUMBER)

# set up the reference release
report "### Validation summary"
setup_release "reference" CMSSW_10_4_0_pre2
report "Reference release [CMSSW_10_4_0_pre2](https://github.com/cms-sw/cmssw/tree/CMSSW_10_4_0_pre2) at $(< $BASE/reference/hash)"
build_matrix "reference" "$REFERENCE_WORKFLOW"
DIRECTORIES="reference"
upload_report $ISSUE_NUMBER $COMMENT_ID

# set up the current development branch
setup_development_release "development" CMSSW_10_4_0_pre2_Patatrack CMSSW_10_4_X_Patatrack $REPOSITORY
report "Development branch [CMSSW_10_4_X_Patatrack](https://github.com/$REPOSITORY/cmssw/tree/CMSSW_10_4_X_Patatrack) at $(< $BASE/development/hash)"
build_matrix "development" "$WORKFLOWS"
DIRECTORIES+=" development"
upload_report $ISSUE_NUMBER $COMMENT_ID

# set up the development branch plus the PR(s) to be tested
if [ "$*" ]; then
  clone_release "development" "testing"
  report "Testing PRs:"
  for PR in "$@"; do
    git cms-merge-topic "$REPOSITORY:$PR"
    echo $PR >> $BASE/testing/PRs
    report "  - #$PR at $(git rev-parse --short=12 "$REPOSITORY/refs/pull/$PR/head")"
  done
  git rev-parse --short=12 HEAD > ../hash
  USER_CXXFLAGS="-g -rdynamic" USER_CUDA_FLAGS="-g -lineinfo" scram b -j
  build_matrix "testing" "$WORKFLOWS"
  DIRECTORIES+=" testing"
fi
report
upload_report $ISSUE_NUMBER $COMMENT_ID

# compute a unique hash for this validation run
JOBID=$({ echo $SCRIPTHASH; cat $(apply_and_glob "$BASE/%/hash" $DIRECTORIES); } | sha1sum | cut -d' ' -f1)
echo $JOBID > $BASE/jobid

# run the workflows
run_workflows $DIRECTORIES
upload_report $ISSUE_NUMBER $COMMENT_ID
# make validation plots
make_validation_plots $DIRECTORIES
upload_report $ISSUE_NUMBER $COMMENT_ID
# upload DQM plots to the GUI
#upload_dqm_plots $DIRECTORIES
#upload_report $ISSUE_NUMBER $COMMENT_ID
# upload nvprof profiles
upload_profiles $DIRECTORIES
upload_report $ISSUE_NUMBER $COMMENT_ID

# restore the original descriptors, close and upload the log files
exec 1>&3- 2>&4-
upload_log_files $DIRECTORIES

echo "This report can be found at $REPORT:"
echo
cat $REPORT

# post the report to GitHub
upload_final_report $ISSUE_NUMBER $COMMENT_ID
