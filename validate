#! /bin/bash -e

# Script for testing one or more pull requests against a reference release and an intermediate development release
#
# Usage:
#   validate [PR ...]
#
# Note: this script relies on `visDQMUpload` and `visDQMUtils.py` being available in the same directory.
# If they are missing they are automatically downloaded from https://github.com/rovere/dqmgui/ .

# hash of this script
SCRIPTHASH=$(sha1sum ${BASH_SOURCE[0]} | cut -d' ' -f1)

BASE=$(mktemp -d -p $PWD run.XXXXXXXXXX)
REPORT=$BASE/report.md

# save the original file descriptors, then redirect all output and errors to a log file
exec 3>&1 4>&2
exec &> $BASE/log

# repository with the working branch and pull requests
REPOSITORY=cms-patatrack

# matrix workflows, default global tag and number of events
REFERENCE_WORKFLOW="10824.5"
WORKFLOWS="10824.5 10824.8 10824.7 10824.9"
GLOBALTAG="101X_upgrade2018_realistic_v7"
NUMEVENTS=100

# datasets used as input for the matrix-like tests
SAMPLES="TTBAR ZMUMU"
TTBAR="/RelValTTbar_13/CMSSW_10_2_0_pre3-PU25ns_101X_upgrade2018_realistic_v7-v1/GEN-SIM-DIGI-RAW"
TTBAR_NUMEVENTS=100
ZMUMU="/RelValZMM_13/CMSSW_10_2_0_pre3-101X_upgrade2018_realistic_v7-v1/GEN-SIM-DIGI-RAW"
ZMUMU_NUMEVENTS=200

# optionally, local cache of the input files
TTBAR_CACHE_PATH="file:/data/store/relval/CMSSW_10_2_0_pre3/RelValTTbar_13/GEN-SIM-DIGI-RAW/PU25ns_101X_upgrade2018_realistic_v7-v1/20000/"
TTBAR_CACHE_FILE="743848D5-8953-E811-8B0A-0CC47A4D769A.root,12589245-8A53-E811-934B-0CC47A78A496.root"
ZMUMU_CACHE_PATH="file:/data/store/relval/CMSSW_10_2_0_pre3/RelValZMM_13/GEN-SIM-DIGI-RAW/101X_upgrade2018_realistic_v7-v1/20000/"
ZMUMU_CACHE_FILE="0055E185-E852-E811-99EA-0CC47A78A496.root,B8145888-E852-E811-8CC1-0025905A612C.root"

# DQM files produced by step4
DQMFILE="DQM_V0001_R000000001__Global__CMSSW_X_Y_Z__RECO.root"

# URL and local area for uploading validation plots, profiles and logs
UPLOAD_URL="https://fwyzard.web.cern.ch/fwyzard/patatrack/pulls"
UPLOAD_DIR="/eos/user/f/fwyzard/www/patatrack/pulls"

# URL of the DQM GUI used to upload files
DQMGUI_URL="http://dqmgui7.cern.ch:8060/dqm/dev"

# full path to visDQMUpload
DQMGUI_UPLOAD=$(dirname $(readlink -f ${BASH_SOURCE[0]}))/visDQMUpload
if ! [ -x $DQMGUI_UPLOAD ]; then
  DQMGUIREPO="https://raw.githubusercontent.com/rovere/dqmgui/index128"
  wget -q "$DQMGUIREPO/bin/visDQMUpload" "$DQMGUIREPO/src/python/DQM/visDQMUtils.py" -nd -P $(dirname $DQMGUI_UPLOAD)/
  chmod +x $DQMGUI_UPLOAD
fi

# use locally installed releases
export SCRAM_ARCH=slc7_amd64_gcc700
source /data/cmssw/cmsset_default.sh


function report() {
  echo "$@" >> $REPORT
}

function apply() {
  PATTERN="$1"; shift
    for ARG; do echo $PATTERN | sed -e"s/%/$ARG/g"; done
}

function apply_and_glob() {
  echo $(apply "$@")
}

function setup_release() {
  local DIRNAME="$1"
  local RELEASE="$2"
  # set up the reference area
  cd $BASE
  echo "# set up $DIRNAME environment for release $RELEASE"
  scram project -n $DIRNAME CMSSW $RELEASE
  cd $DIRNAME/src
  eval $(scram runtime -sh)
  git cms-init --upstream-only
  echo
  # <add here any required pull request or external update>
  #git cms-addpkg HeterogeneousCore
  #scram b -j`nproc`
  git rev-parse --short=12 HEAD > .hash
  echo
}

function setup_development_release() {
  local DIRNAME="$1"
  local RELEASE="$2"
  local BRANCH="$3"
  setup_release $DIRNAME $RELEASE
  # <add here any required pull request or external update>
  git cms-remote add $REPOSITORY
  git checkout $REPOSITORY/$BRANCH -b $BRANCH
  git cms-addpkg $(git diff $CMSSW_VERSION --name-only | cut -d/ -f-2 | sort -u) || true
  git cms-checkdeps -a
  scram b -j`nproc`
  git rev-parse --short=12 HEAD > .hash
  if [ $(git rev-parse $RELEASE) != $(git rev-parse HEAD) ]; then
    echo "# update $DIRNAME environment on branch $BRANCH with"
    git log --oneline --reverse --no-decorate ${RELEASE}..
  fi
  echo
}

function setup_patatrack_release() {
  local DIRNAME="$1"
  local RELEASE="$2"
  local BRANCH="$3"
  # set up the reference area
  cd "$BASE"
  echo "# set up $DIRNAME environment for release $RELEASE"
  scram project -n $DIRNAME CMSSW $RELEASE
  cd $DIRNAME/src
  eval $(scram runtime -sh)
  # git needs some special care
  git cms-init --upstream-only || true
  git config core.sparsecheckout true
  {
    echo "/.gitignore"
    echo "/.clang-tidy"
    echo "/.clang-format"
  } > $CMSSW_BASE/src/.git/info/sparse-checkout
  git read-tree -mu HEAD
  git cms-remote add cms-patatrack
  git fetch cms-patatrack $BRANCH:$BRANCH $RELEASE:from-$RELEASE
  git branch $BRANCH -u cms-patatrack/$BRANCH
  git branch from-$RELEASE -u cms-patatrack/$BRANCH
  git checkout from-$RELEASE

  # <add here any required pull request or external update>
  scram b -j`nproc`
  git rev-parse --short=12 HEAD > .hash
  if [ $(git rev-parse $RELEASE) != $(git rev-parse HEAD) ]; then
    echo "# update $DIRNAME environment on branch $BRANCH with"
    git log --oneline --reverse --no-decorate ${RELEASE}..
  fi
  echo
}

function clone_release() {
  local SOURCE="$1"
  local TARGET="$2"
  cd "$BASE"
  cp -ar "$SOURCE" "$TARGET"
  cd "$TARGET"/src
  scram b ProjectRename
  eval $(scram runtime -sh)
  echo
}

function build_matrix() {
  local DIRNAME="$1"
  shift
  local WORKFLOWS="$@"
  local SAMPLE DATASET WORKDIR CACHE_PATH CACHE_FILE INPUT MY_GLOBALTAG MY_NUMEVENTS WORKFLOW STEP3 STEP4
  # create the matrix-like workflows for the various samples
  cd $BASE/$DIRNAME
  eval $(scram runtime -sh)
  for SAMPLE in $SAMPLES; do
    DATASET=${!SAMPLE}
    WORKDIR=$(echo $DATASET | cut -d/ -f 2-3 --output-delimiter=-)
    CACHE_PATH=$(eval echo \$$(echo $SAMPLE)_CACHE_PATH)
    CACHE_FILE=$(eval echo \$$(echo $SAMPLE)_CACHE_FILE)
    if [ "$CACHE_PATH" ] && [ "$CACHE_FILE" ]; then
      INPUT="--dirin=$CACHE_PATH --filein $CACHE_FILE"
    else
      INPUT="--dasquery 'file dataset=$DATASET'"
    fi
    # customise the global tag and number of events by dataset, or use the default values
    MY_GLOBALTAG=$(eval echo \$$(echo $SAMPLE)_GLOBALTAG)
    MY_NUMEVENTS=$(eval echo \$$(echo $SAMPLE)_NUMEVENTS)
    echo "# prepare to run on ${MY_NUMEVENTS:=$NUMEVENTS} events on $DATASET with ${MY_GLOBALTAG:=$GLOBALTAG} conditions"
    mkdir -p $CMSSW_BASE/run/$WORKDIR
    cd $CMSSW_BASE/run/$WORKDIR
    for WORKFLOW in $WORKFLOWS; do
      # check the the workflow actually exists in the release
      runTheMatrix.py -n -e -l $WORKFLOW | grep -q ^$WORKFLOW || continue
      mkdir -p $WORKFLOW
      cd $WORKFLOW
      # extract step3 and step4 commands
      STEP3="$(runTheMatrix.py -n -e -l $WORKFLOW | grep 'cmsDriver.py step3' | cut -d: -f2- | sed -e"s/^ *//" -e"s/ \+--conditions *[^ ]\+/ --conditions $MY_GLOBALTAG/" -e"s/ \+-n *[^ ]\+/ -n $MY_NUMEVENTS/") --fileout file:step3.root"
      STEP4="$(runTheMatrix.py -n -e -l $WORKFLOW | grep 'cmsDriver.py step4' | cut -d: -f2- | sed -e"s/^ *//" -e"s/ \+--conditions *[^ ]\+/ --conditions $MY_GLOBALTAG/" -e"s/ \+-n *[^ ]\+/ -n $MY_NUMEVENTS/") --filein file:step3_inDQM.root"
      echo "# prepare workflow $WORKFLOW"
      $STEP3 $INPUT --no_exec --python_filename=step3.py
      $STEP4        --no_exec --python_filename=step4.py
      # add the NVProfilerService to step3
      sed -i step3.py -e '/\# End of customisation functions/i \
# Mark CMSSW transitions and modules in the nvprof profile\
from FWCore.ParameterSet.Utilities import moduleLabelsInSequences\
process.NVProfilerService = cms.Service("NVProfilerService",\
    highlightModules = cms.untracked.vstring( moduleLabelsInSequences(process.reconstruction_step) ),\
    showModulePrefetching = cms.untracked.bool( False )\
)\
'
      cd ..
    done
    echo
  done
}

function run_workflows() {
  local WORKDIR
  cd $BASE
  for WORKDIR in $(apply_and_glob "%/run/*/*/" "$@"); do
    cd $BASE/$WORKDIR
    echo "# at $WORKDIR"
    eval $(scram runtime -sh)
    echo -n "# running step3... "
    if nvprof -f -o step3.nvprof -s --log-file step3.profile -- cmsRun step3.py >& step3.log; then
      echo "done"
    else
      echo "failed"
      tail step3.log
      # do not attempt to run step4 is step3 failed
      continue
    fi
    echo -n "# running step4... "
    if cmsRun step4.py >& step4.log; then
      echo "done"
    else
      echo "failed"
      tail step4.log
    fi
  done
  cd $BASE
}

# Make validation plots, based on the DQM output of step4 and makeTrackValidationPlots.py
# and upload them to the EOS www area.
#
# Usage:
#   make_valdation_plots REFERENCE_RELEASE [[RELEASE ...] TARGET_RELEASE]
#
function make_valdation_plots() {
  [ "$1" ] || return 1
  local DIRNAME="${!#}"
  local REFERENCE_RELEASE="$1"
  local -a RELEASES=("$@")
  shift
  local -a TESTING_RELEASES=($@)
  cd $BASE/$DIRNAME
  eval $(scram runtime -sh)

  report "### \`makeTrackValidationPlots.py\` plots"

  local SAMPLE
  for SAMPLE in $SAMPLES; do
    local DATASET=${!SAMPLE}
    report "#### $DATASET"
    local WORKDIR=$(echo $DATASET | cut -d/ -f 2-3 --output-delimiter=-)
    mkdir -p $BASE/plots/$WORKDIR
    cd $BASE/plots/$WORKDIR

    # reference release and workflow
    local FILE=$BASE/$REFERENCE_RELEASE/run/$WORKDIR/$REFERENCE_WORKFLOW/$DQMFILE
    [ -f $FILE ] && ln -s $FILE ${REFERENCE_RELEASE}-${REFERENCE_WORKFLOW}.root

    # development releases and workflows
    local RELEASE
    for RELEASE in ${TESTING_RELEASES[@]}; do
      local WORKFLOW
      for WORKFLOW in $WORKFLOWS; do
        local FILE=$BASE/$RELEASE/run/$WORKDIR/$WORKFLOW/$DQMFILE
        [ -f $FILE ] && ln -s $FILE ${RELEASE}-${WORKFLOW}.root
      done
    done

    # validation of all workflows across all releases
    local WORKFLOW
    for WORKFLOW in $WORKFLOWS; do
      mkdir -p $UPLOAD_DIR/$JOBID/$WORKDIR/$WORKFLOW
      if [ "$WORKFLOW" == "$REFERENCE_WORKFLOW" ]; then
        # reference workflow
        makeTrackValidationPlots.py \
          --html-sample $DATASET \
          --html-validation-name $DATASET \
          --outputDir $UPLOAD_DIR/$JOBID/$WORKDIR/$REFERENCE_WORKFLOW \
          ${RELEASES[@]/%/-${REFERENCE_WORKFLOW}.root}
      else
        # other workflows
        [ "${TESTING_RELEASES[0]}" ] || continue
        makeTrackValidationPlots.py \
          --html-sample $DATASET \
          --html-validation-name $DATASET \
          --outputDir $UPLOAD_DIR/$JOBID/$WORKDIR/$WORKFLOW \
          ${TESTING_RELEASES[0]}-${REFERENCE_WORKFLOW}.root \
          ${TESTING_RELEASES[@]/%/-${WORKFLOW}.root}
      fi
      report "  - [tracking validation plots]($UPLOAD_URL/$JOBID/$WORKDIR/$WORKFLOW/index.html) for workflow $WORKFLOW"
    done
    report
  done
}

# Build a link to the DQM GUI showing one or more test results
#
# Usage:
#   build_dqm_link REFERENCE_DATASET [DATASET ...]
#
function build_dqm_link() {
  local URL="$DQMGUI_URL/start?runnr=1;"
  URL+="dataset=$1;"
  URL+="sampletype=offline_relval;"
  URL+="filter=all;"
  URL+="referencepos=ratiooverlay;"
  URL+="referenceshow=all;"
  URL+="referencenorm=False;"
  if [ "$2" ]; then
    URL+="referenceobj1=other%3A%3A$2%3A;"
  else
    URL+="referenceobj1=none;"
  fi
  if [ "$3" ]; then
    URL+="referenceobj2=other%3A%3A$3%3A;"
  else
    URL+="referenceobj2=none;"
  fi
  if [ "$4" ]; then
    URL+="referenceobj3=other%3A%3A$4%3A;"
  else
    URL+="referenceobj3=none;"
  fi
  if [ "$5" ]; then
    URL+="referenceobj4=other%3A%3A$5%3A;"
  else
    URL+="referenceobj4=none;"
  fi
  URL+="search=;"
  URL+="striptype=object;"
  URL+="stripruns=;"
  URL+="stripaxis=run;"
  URL+="stripomit=none;"
  URL+="workspace=Everything;"
  URL+="size=L;"
  URL+="root=Tracking;"
  URL+="focus=;"
  URL+="zoom=no;"
  echo "$URL"
}

# Usage:
#   build_dqm_dataset RELEASE DATASET WORKFLOW
function build_dqm_dataset() {
  local RELEASE="$1"
  local DATASET="$2"
  local WORKFLOW="$3"
  local HASH=$(<$BASE/$RELEASE/src/.hash)
  echo "$(echo $DATASET | cut -d/ -f-3)-${HASH}/${WORKFLOW/./_}"
}


# Usage:
#   build_dqm_filename RELEASE DATASET WORKFLOW
function build_dqm_filename() {
  local RELEASE="$1"
  local DATASET="$2"
  local WORKFLOW="$3"
  local NAME=$(echo $DATASET | cut -d/ -f-3 | sed -e's|/|__|g')
  local HASH=$(<$BASE/$RELEASE/src/.hash)
  echo "DQM_V0001_R000000001${NAME}-${HASH}__${WORKFLOW/./_}.root"
}


# Upload DQM plots to the GUI.
#
# Usage:
#   upload_dqm_plots REFERENCE_RELEASE [[RELEASE ...] TARGET_RELEASE]
#
function upload_dqm_plots() {
  [ "$1" ] || return 1
  local REFERENCE_RELEASE="$1"; shift
  local RELEASES=("$@")

  report "### DQM GUI plots"

  local SAMPLE
  for SAMPLE in $SAMPLES; do
    local DATASET=${!SAMPLE}
    report "#### $DATASET"
    local WORKDIR=$(echo $DATASET | cut -d/ -f 2-3 --output-delimiter=-)
    mkdir -p $BASE/dqm/$WORKDIR
    cd $BASE/dqm/$WORKDIR

    # reference release and workflow
    local DQMGUI_FILEFILE=$(build_dqm_filename $REFERENCE_RELEASE $DATASET $REFERENCE_WORKFLOW)
    local FILE=$BASE/$REFERENCE_RELEASE/run/$WORKDIR/$REFERENCE_WORKFLOW/$DQMFILE
    if [ -f $FILE ]; then
      ln -s $FILE $DQMGUI_FILEFILE
      report "  - reference [DQM plots]($(build_dqm_link $(build_dqm_dataset $REFERENCE_RELEASE $DATASET $REFERENCE_WORKFLOW))) for $REFERENCE_RELEASE release, workflow $REFERENCE_WORKFLOW"
    else
      report "  - reference DQM plots for $REFERENCE_RELEASE release, workflow $REFERENCE_WORKFLOW are **missing**"
    fi

    # development releases and workflows
    local RELEASE
    for RELEASE in ${RELEASES[@]}; do
      local WORKFLOW
      for WORKFLOW in $WORKFLOWS; do
        local DQMGUI_FILEFILE=$(build_dqm_filename $RELEASE $DATASET $WORKFLOW)
        local FILE=$BASE/$RELEASE/run/$WORKDIR/$WORKFLOW/$DQMFILE
        if [ -f $FILE ]; then
          ln -s $FILE $DQMGUI_FILEFILE
          report "  - [DQM plots]($(build_dqm_link $(build_dqm_dataset $RELEASE $DATASET $WORKFLOW))) for $RELEASE release, workflow $WORKFLOW"
        else
          report "  - DQM plots for $RELEASE release, workflow $WORKFLOW are **missing**"
        fi
      done
    done

    # upload all DQM files in the background
    $DQMGUI_UPLOAD $DQMGUI_URL DQM_*.root >& upload.log &

    # DQM-based validation of all workflows across all releases
    local WORKFLOW
    for WORKFLOW in $WORKFLOWS; do
      if [ "$WORKFLOW" == "$REFERENCE_WORKFLOW" ]; then
        # reference workflow
        local LINK=$(build_dqm_link \
          $(for RELEASE in ${REFERENCE_RELEASE} ${RELEASES[@]}; do build_dqm_dataset $RELEASE $DATASET $WORKFLOW; done) \
        )
        report "  - [DQM comparison]($LINK) for reference workflow $WORKFLOW"
      else
        # other workflows
        [ "${RELEASES[0]}" ] || continue
        local LINK=$(build_dqm_link \
          $(build_dqm_dataset ${RELEASES[0]} $DATASET $REFERENCE_WORKFLOW) \
          $(for RELEASE in ${RELEASES[@]}; do build_dqm_dataset $RELEASE $DATASET $WORKFLOW; done) \
        )
        report "  - [DQM comparison]($LINK) for workflow $WORKFLOW"
      fi
    done
    report

  done
}

# Upload nvprof profiles
#
# Usage:
#   upload_profiles REFERENCE_RELEASE [[RELEASE ...] TARGET_RELEASE]
#
function upload_profiles() {
  [ "$1" ] || return 1
  local REFERENCE_RELEASE="$1"
  local -a RELEASES=("$@")
  shift
  local -a TESTING_RELEASES=($@)

  report "### \`nvprof/nvvp\` profiles"

  local SAMPLE
  for SAMPLE in $SAMPLES; do
    local DATASET=${!SAMPLE}
    report "#### $DATASET"
    local WORKDIR=$(echo $DATASET | cut -d/ -f 2-3 --output-delimiter=-)

    # reference release and workflow
    local FILE=$BASE/$REFERENCE_RELEASE/run/$WORKDIR/$REFERENCE_WORKFLOW/step3.nvprof
    if [ -f $FILE ]; then
      cp $FILE $UPLOAD_DIR/$JOBID/$WORKDIR/$REFERENCE_RELEASE-$REFERENCE_WORKFLOW-step3.nvprof
      report "  - $REFERENCE_RELEASE [profile]($UPLOAD_URL/$JOBID/$WORKDIR/$REFERENCE_RELEASE-$REFERENCE_WORKFLOW-step3.nvprof) for workflow $REFERENCE_WORKFLOW"
    fi

    # development releases and workflows
    local RELEASE
    for RELEASE in ${TESTING_RELEASES[@]}; do
      local WORKFLOW
      for WORKFLOW in $WORKFLOWS; do
        local FILE=$BASE/$RELEASE/run/$WORKDIR/$WORKFLOW/step3.nvprof
        if [ -f $FILE ]; then
          cp $FILE $UPLOAD_DIR/$JOBID/$WORKDIR/$RELEASE-$WORKFLOW-step3.nvprof
          report "  - $RELEASE [profile]($UPLOAD_URL/$JOBID/$WORKDIR/$RELEASE-$WORKFLOW-step3.nvprof) for workflow $WORKFLOW"
        fi
      done
    done
    report
  done
}

# Upload the log file
#
# Usage:
#   upload_log_files REFERENCE_RELEASE [[RELEASE ...] TARGET_RELEASE]
#
# Note: the releases are used to build the hash of the upload area
#
function upload_log_files() {
  [ "$1" ] || return 1
  local -a RELEASES=("$@")

  cp $BASE/log $UPLOAD_DIR/$JOBID/log
  report "### Logs"
  report "The full log is available at $UPLOAD_URL/$JOBID/log ."
}

# main
touch $REPORT

# set up the reference release
setup_release "reference" CMSSW_10_2_0_pre4
report "Reference release [CMSSW_10_2_0_pre4](https://github.com/cms-sw/cmssw/tree/CMSSW_10_2_0_pre4) at $(< $BASE/reference/src/.hash)"
build_matrix "reference" "$REFERENCE_WORKFLOW"
DIRECTORIES="reference"

# set up the current development branch
setup_patatrack_release "development" CMSSW_10_2_0_pre4_Patatrack CMSSW_10_2_X_Patatrack
#setup_development_release "development" CMSSW_10_2_0_pre4 CMSSW_10_2_X_Patatrack
report "Development branch [CMSSW_10_2_X_Patatrack](https://github.com/cms-patatrack/cmssw/tree/CMSSW_10_2_X_Patatrack) at $(< $BASE/development/src/.hash)"
build_matrix "development" "$WORKFLOWS"
DIRECTORIES+=" development"

# set up the development branch plus the PR(s) to be tested
if [ "$*" ]; then
  clone_release "development" "testing"
  report "Testing PRs:"
  for PR in "$@"; do
    git cms-merge-topic "$REPOSITORY:$PR"
    report "  - #$PR at $(git rev-parse --short=12 "$REPOSITORY/refs/pull/$PR/head")"
  done
  git rev-parse --short=12 HEAD > .hash
  scram b -j`nproc`
  build_matrix "testing" "$WORKFLOWS"
  DIRECTORIES+=" testing"
fi
report

# compute a unique hash for this validation run
JOBID=$({ echo $SCRIPTHASH; cat $(apply_and_glob "$BASE/%/src/.hash" $DIRECTORIES); } | sha1sum | cut -d' ' -f1)

# run the workflows
run_workflows $DIRECTORIES
# make validation plots
make_valdation_plots $DIRECTORIES
# upload DQM plots to the GUI
upload_dqm_plots $DIRECTORIES
# upload nvprof profiles
upload_profiles $DIRECTORIES

# restore the original descriptors, close and upload the log files
exec 1>&3- 2>&4-
upload_log_files $DIRECTORIES

echo "This report can be found at $REPORT:"
echo
cat $REPORT
