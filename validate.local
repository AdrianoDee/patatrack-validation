#! /bin/bash -e

# Script for testing one or more pull requests against a reference release and an intermediate development release
#
# Usage:
#   validate [PR ...]
#
# Note: this script relies on `visDQMUpload` and `visDQMUtils.py` being available in the same directory.
# If they are missing they are automatically downloaded from https://github.com/rovere/dqmgui/ .

# matrix workflows, default global tag and number of events
REFERENCE_WORKFLOW="10824.5"
WORKFLOWS="10824.5 10824.8 10824.7 10824.9"
PROFILING="10824.5 10824.8 10824.7 10824.9"
MEMCHECKS="10824.8 10824.9"
GLOBALTAG="103X_upgrade2018_realistic_v7"
NUMEVENTS=100
THREADS=1
STREAMS=1

# cuda-memcheck tools options
INITCHECK_OPTS="--track-unused-memory no"
MEMCHECK_OPTS="--leak-check full --report-api-errors all"
SYNCCHECK_OPTS=""

# datasets used as input for the matrix-like tests
SAMPLES="TTBAR ZMUMU"
TTBAR="/RelValTTbar_13/CMSSW_10_4_0_pre1-PU25ns_103X_upgrade2018_realistic_v7-v1/GEN-SIM-DIGI-RAW"
TTBAR_NUMEVENTS=100
ZMUMU="/RelValZMM_13/CMSSW_10_4_0_pre1-103X_upgrade2018_realistic_v7-v1/GEN-SIM-DIGI-RAW"
ZMUMU_NUMEVENTS=200

# optionally, local cache of the input files
TTBAR_CACHE_PATH="file:/data/store/relval/CMSSW_10_4_0_pre1/RelValTTbar_13/GEN-SIM-DIGI-RAW/PU25ns_103X_upgrade2018_realistic_v7-v1/10000"
TTBAR_CACHE_FILE="D715F458-5B7D-C04A-8252-A8F638739EFF.root"
ZMUMU_CACHE_PATH="file:/data/store/relval/CMSSW_10_4_0_pre1/RelValZMM_13/GEN-SIM-DIGI-RAW/103X_upgrade2018_realistic_v7-v1/10000"
ZMUMU_CACHE_FILE="7D4AB74F-342B-F545-8BF7-2DFC999025DE.root"

# DQM files produced by step4
DQMFILE="DQM_V0001_R000000001__Global__CMSSW_X_Y_Z__RECO.root"

function report() {
  echo "$@"
}

function has_profiling() {
  local WORKFLOW=$1
  echo "$PROFILING" | grep -q -w "$WORKFLOW"
}

function has_memcheck() {
  local WORKFLOW=$1
  echo "$MEMCHECKS" | grep -q -w "$WORKFLOW"
}

function build_matrix() {
  local WORKFLOWS="$@"
  local SAMPLE DATASET WORKDIR CACHE_PATH CACHE_FILE INPUT MY_GLOBALTAG MY_NUMEVENTS WORKFLOW STEP3 STEP4
  # create the matrix-like workflows for the various samples
  cd $CMSSW_BASE
  for SAMPLE in $SAMPLES; do
    DATASET=${!SAMPLE}
    WORKDIR=$(echo $DATASET | cut -d/ -f 2-3 --output-delimiter=-)
    CACHE_PATH=$(eval echo \$$(echo $SAMPLE)_CACHE_PATH)
    CACHE_FILE=$(eval echo \$$(echo $SAMPLE)_CACHE_FILE)
    if [ "$CACHE_PATH" ] && [ "$CACHE_FILE" ]; then
      INPUT="--dirin=$CACHE_PATH --filein $CACHE_FILE"
    else
      INPUT="--dasquery 'file dataset=$DATASET'"
    fi
    # customise the global tag and number of events by dataset, or use the default values
    MY_GLOBALTAG=$(eval echo \$$(echo $SAMPLE)_GLOBALTAG)
    MY_NUMEVENTS=$(eval echo \$$(echo $SAMPLE)_NUMEVENTS)
    echo "# prepare to run on ${MY_NUMEVENTS:=$NUMEVENTS} events on $DATASET with ${MY_GLOBALTAG:=$GLOBALTAG} conditions"
    mkdir -p $CMSSW_BASE/run/$WORKDIR
    cd $CMSSW_BASE/run/$WORKDIR
    for WORKFLOW in $WORKFLOWS; do
      # check the the workflow actually exists in the release
      runTheMatrix.py -n -e -l $WORKFLOW | grep -q ^$WORKFLOW || continue
      mkdir -p $WORKFLOW
      cd $WORKFLOW
      # extract step3 and step4 commands
      STEP3="$(runTheMatrix.py -n -e -l $WORKFLOW | grep 'cmsDriver.py step3' | cut -d: -f2- | sed -e"s/^ *//" -e"s/ \+--conditions *[^ ]\+/ --conditions $MY_GLOBALTAG/" -e"s/ \+-n *[^ ]\+/ -n $MY_NUMEVENTS/") --fileout file:step3.root"
      STEP4="$(runTheMatrix.py -n -e -l $WORKFLOW | grep 'cmsDriver.py step4' | cut -d: -f2- | sed -e"s/^ *//" -e"s/ \+--conditions *[^ ]\+/ --conditions $MY_GLOBALTAG/" -e"s/ \+-n *[^ ]\+/ -n $MY_NUMEVENTS/") --filein file:step3_inDQM.root"
      echo "# prepare workflow $WORKFLOW"
      $STEP3 $INPUT --no_exec --python_filename=step3.py
      $STEP4        --no_exec --python_filename=step4.py
      # add the NVProfilerService to step3
      sed -i step3.py -e '/\# End of customisation functions/i \
# Mark CMSSW transitions and modules in the nvprof profile\
from FWCore.ParameterSet.Utilities import moduleLabelsInSequences\
process.NVProfilerService = cms.Service("NVProfilerService",\
    highlightModules = cms.untracked.vstring( moduleLabelsInSequences(process.reconstruction_step) ),\
    showModulePrefetching = cms.untracked.bool( False )\
)\
\
# Show CUDAService messages\
process.MessageLogger.categories.append("CUDAService")\
'
      echo >> step3.py
      echo "# Configure multithreading" >> step3.py
      echo "process.options.numberOfThreads = cms.untracked.uint32( $THREADS )" >> step3.py
      echo "process.options.numberOfStreams = cms.untracked.uint32( $STREAMS )" >> step3.py

      local CUSTOMISE=RecoPixelVertexing/Configuration/customizePixelTracksForProfiling
      if has_profiling $WORKFLOW && ( [ -f $CMSSW_RELEASE_BASE/python/${CUSTOMISE}.py ] || [ -f $CMSSW_BASE/python/${CUSTOMISE}.py ] ); then
        # mark the workflow to run the profiling job
        touch .has_profiling
        # create a profiling workflow
        $STEP3 $INPUT --no_exec --customise ${CUSTOMISE}.customizePixelTracksForProfiling --python_filename=profile.py
        # add the NVProfilerService to profile
        sed -i profile.py -e '/\# End of customisation functions/i \
# Mark CMSSW transitions and modules in the nvprof profile\
from FWCore.ParameterSet.Utilities import moduleLabelsInSequences\
process.NVProfilerService = cms.Service("NVProfilerService",\
    highlightModules = cms.untracked.vstring( moduleLabelsInSequences(process.reconstruction_step) ),\
    showModulePrefetching = cms.untracked.bool( False )\
)\
\
# Show CUDAService messages\
process.MessageLogger.categories.append("CUDAService")\
'
        echo >> profile.py
        echo "# Configure multithreading" >> profile.py
        echo "process.options.numberOfThreads = cms.untracked.uint32( $THREADS )" >> profile.py
        echo "process.options.numberOfStreams = cms.untracked.uint32( $STREAMS )" >> profile.py
      fi

      if has_memcheck $WORKFLOW; then
        # prepare the workflow to run the various cuda-memcheck checks
        cp step3.py memcheck.py
        echo >> memcheck.py
        echo '# limit he number of events for cuda-memcheck' >> memcheck.py
        echo 'process.maxEvents.input = 10' >> memcheck.py
      fi

      cd ..
    done
    echo
  done
}

function run_workflow() {
  local WORKDIR=$1
  local STEP3_SUCCESS

  cd $CMSSW_BASE/$WORKDIR
  echo "# at $WORKDIR"

  # run step 3
  echo -n "# running step3... "
  if nvprof -f -o step3.nvvp -s --log-file step3.profile -- cmsRun step3.py >& step3.log; then
    STEP3_SUCCESS=true
    echo "done"
  else
    STEP3_SUCCESS=false
    echo "failed"
    tail step3.log
  fi

  # do not attempt to run step4 or profile if step3 failed
  if $STEP3_SUCCESS; then
    # run step 4
    echo -n "# running step4... "
    if cmsRun step4.py >& step4.log; then
      echo "done"
    else
      echo "failed"
      tail step4.log
    fi

    # (optional) run profile
    if [ -f .has_profiling ]; then
      echo -n "# running profile... "
      if nvprof -f -o profile.nvvp -s --log-file profile.profile -- cmsRun profile.py >& profile.log; then
        echo "done"
      else
        echo "failed"
        tail profile.log
      fi
    fi
  fi

  # (optional) run cuda-memcheck
  if [ -f memcheck.py ]; then
    # initcheck
    echo -n "# running cuda-memcheck --tool initcheck... "
    if cuda-memcheck --tool initcheck --error-exitcode 127 $INITCHECK_OPTS --log-file cuda-initcheck.log -- cmsRun step3.py >& step3-initcheck.log; then
      [ -f step3-initcheck.log ] && cat step3-initcheck.log | c++filt -i > demangled && mv demangled step3-initcheck.log
      echo "done"
      touch cuda-initcheck.done
    else
      echo "failed"
      tail cuda-initcheck.log
      touch cuda-initcheck.fail
    fi
    # memcheck
    echo -n "# running cuda-memcheck --tool memcheck... "
    if cuda-memcheck --tool memcheck --error-exitcode 127 $MEMCHECK_OPTS --log-file cuda-memcheck.log -- cmsRun step3.py >& step3-memcheck.log; then
      [ -f step3-memcheck.log ] && cat step3-memcheck.log | c++filt -i > demangled && mv demangled step3-memcheck.log
      echo "done"
      touch cuda-memcheck.done
    else
      echo "failed"
      tail cuda-memcheck.log
      touch cuda-memcheck.fail
    fi
    # synccheck
    echo -n "# running cuda-memcheck --tool synccheck... "
    if cuda-memcheck --tool synccheck --error-exitcode 127 $SYNCCHECK_OPTS --log-file cuda-synccheck.log -- cmsRun step3.py >& step3-synccheck.log; then
      [ -f step3-synccheck.log ] && cat step3-synccheck.log | c++filt -i > demangled && mv demangled step3-synccheck.log
      echo "done"
      touch cuda-synccheck.done
    else
      echo "failed"
      tail cuda-synccheck.log
      touch cuda-synccheck.fail
    fi
  fi
}

function run_workflows() {
  local WORKDIR
  local MAXJOBS=4

  cd $CMSSW_BASE
  for WORKDIR in run/*/*/; do
    # run up to MAXJOBS in parallel
    while (( $(jobs | wc -l) >= $MAXJOBS )); do sleep 1; done
    run_workflow $WORKDIR &
  done
  wait
}

# Make validation plots, based on the DQM output of step4 and makeTrackValidationPlots.py
# and upload them to the EOS www area.
#
# Usage:
#   make_validation_plots
#
function make_validation_plots() {
  report "### \`makeTrackValidationPlots.py\` plots"

  local SAMPLE
  for SAMPLE in $SAMPLES; do
    local DATASET=${!SAMPLE}
    report "#### $DATASET"
    local WORKDIR=$(echo $DATASET | cut -d/ -f 2-3 --output-delimiter=-)
    mkdir -p $CMSSW_BASE/plots/$WORKDIR
    cd $CMSSW_BASE/plots/$WORKDIR

    # development releases and workflows
    local WORKFLOW
    for WORKFLOW in $WORKFLOWS; do
      local FILE=$CMSSW_BASE/run/$WORKDIR/$WORKFLOW/$DQMFILE
      [ -f $FILE ] && ln -s $FILE ${WORKFLOW}.root
    done

    # validation of all workflows across all releases
    makeTrackValidationPlots.py \
      --extended \
      --html-sample $DATASET \
      --html-validation-name $DATASET \
      --outputDir plots \
      *.root
    echo
  done
}

# main
cd $CMSSW_BASE
rm -rf run/ plots/

build_matrix "$WORKFLOWS"
# run the workflows
run_workflows
# make validation plots
make_validation_plots
